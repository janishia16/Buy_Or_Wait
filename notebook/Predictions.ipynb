{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e65519-0675-41af-b29c-cf4b5fde9aa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import avg, lag, col, when, lead, max as spark_max\n",
    "\n",
    "# Load the registered model (no need to retrain)\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_uri = \"models:/layers.gold.buy_wait_model/1\"\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "print(\"âœ“ Model loaded\")\n",
    "\n",
    "# Feature columns (must match training)\n",
    "feature_columns = [\"price\", \"avg_7d_price\", \"lag_1_price\", \"lag_7_price\", \n",
    "                   \"pct_change_1d\", \"pct_change_7d\", \"pct_vs_avg\"]\n",
    "\n",
    "# Create features from fresh data\n",
    "base_df = spark.table(\"layers.silver.book_master\")\n",
    "\n",
    "w_avg = (Window.partitionBy(\"source\", \"book_name\").orderBy(\"scrape_date\").rowsBetween(-7, -1))\n",
    "w_lag = (Window.partitionBy(\"source\", \"book_name\").orderBy(\"scrape_date\"))\n",
    "\n",
    "feature_df = base_df \\\n",
    "    .withColumn(\"avg_7d_price\", avg(\"price\").over(w_avg)) \\\n",
    "    .withColumn(\"lag_1_price\", lag(\"price\", 1).over(w_lag)) \\\n",
    "    .withColumn(\"lag_7_price\", lag(\"price\", 7).over(w_lag)) \\\n",
    "    .withColumn(\"pct_change_1d\", (col(\"price\") - col(\"lag_1_price\")) / col(\"lag_1_price\") * 100) \\\n",
    "    .withColumn(\"pct_change_7d\", (col(\"price\") - col(\"lag_7_price\")) / col(\"lag_7_price\") * 100) \\\n",
    "    .withColumn(\"pct_vs_avg\", (col(\"price\") - col(\"avg_7d_price\")) / col(\"avg_7d_price\") * 100)\n",
    "\n",
    "print(\"âœ“ Features created\")\n",
    "\n",
    "\n",
    "# GET TODAY'S RECOMMENDATIONS\n",
    "\n",
    "def get_recommendations(target_date=None):\n",
    "    if target_date is None:\n",
    "        target_date = feature_df.select(spark_max(\"scrape_date\")).collect()[0][0]\n",
    "    \n",
    "    print(f\"\\nðŸ“… Recommendations for: {target_date}\\n\")\n",
    "    \n",
    "    today_features = (feature_df\n",
    "        .filter(col(\"scrape_date\") == target_date)\n",
    "        .filter(col(\"avg_7d_price\").isNotNull())\n",
    "        .filter(col(\"lag_7_price\").isNotNull())\n",
    "        .select(\n",
    "            col(\"book_name\"), col(\"source\"), col(\"url\"),\n",
    "            col(\"price\").alias(\"current_price\"),\n",
    "            col(\"avg_7d_price\"), col(\"lag_1_price\"), col(\"lag_7_price\"),\n",
    "            col(\"pct_change_1d\"), col(\"pct_change_7d\"), col(\"pct_vs_avg\")\n",
    "        )\n",
    "        .toPandas()\n",
    "    )\n",
    "    \n",
    "    if len(today_features) == 0:\n",
    "        print(\"No data for this date\")\n",
    "        return None\n",
    "    \n",
    "    X_predict = today_features[[\"current_price\", \"avg_7d_price\", \"lag_1_price\", \"lag_7_price\", \n",
    "                                 \"pct_change_1d\", \"pct_change_7d\", \"pct_vs_avg\"]].copy()\n",
    "    X_predict.columns = feature_columns\n",
    "    \n",
    "    predictions = loaded_model.predict(X_predict)\n",
    "    probabilities = loaded_model.predict_proba(X_predict)\n",
    "    \n",
    "    today_features[\"recommendation\"] = [\"ðŸŸ¢ BUY\" if p == 1 else \"ðŸ”´ WAIT\" for p in predictions]\n",
    "    today_features[\"confidence\"] = [f\"{max(prob)*100:.1f}%\" for prob in probabilities]\n",
    "    \n",
    "    print(\"ðŸ“Š Summary:\\n\")\n",
    "    for _, row in today_features.sort_values(\"recommendation\", ascending=False).iterrows():\n",
    "        status = \"below avg âœ“\" if row[\"pct_vs_avg\"] < 0 else \"above avg\"\n",
    "        print(f\"{row['recommendation']} {row['book_name']} ({row['source']}): â‚¹{row['current_price']:.0f} ({status}) - {row['confidence']}\")\n",
    "        print(f\"   {row['url']}\\n\")\n",
    "    \n",
    "    return today_features\n",
    "\n",
    "# Run it!\n",
    "get_recommendations()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Predictions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
